{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae58495f-7be2-4969-9c39-e49a5ac35890",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from lmul_nn_funcs import lmul_bits \n",
    "def lmul(a, b, M=7):\n",
    "    return lmul_bits(a, b)\n",
    "\n",
    "#this is the dataset loader\n",
    "#this is used for regressive generation;\n",
    "\n",
    "#needed heavy LLM help to build this notebook out\n",
    "class CharDatasetFixed(torch.utils.data.Dataset):\n",
    "    def __init__(self, sentences, pad_char=\" \", seq_len=64):\n",
    "        self.pad_char = pad_char\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "        # include pad_char explicitly\n",
    "        all_text = \"\".join(sentences) + pad_char\n",
    "        chars = sorted(list(set(all_text)))   # now pad_char is in chars\n",
    "        self.stoi = {c:i for i,c in enumerate(chars)}\n",
    "        self.itos = {i:c for c,i in self.stoi.items()}\n",
    "        self.vocab = len(chars)\n",
    "\n",
    "        # convert sentences to indices and pad\n",
    "        self.data = []\n",
    "        for s in sentences:\n",
    "            s_fixed = s[:seq_len].ljust(seq_len, pad_char)\n",
    "            self.data.append(torch.tensor([self.stoi[c] for c in s_fixed]))\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s = self.data[idx]\n",
    "        x = s[:-1]  # input sequence\n",
    "        y = s[1:]   # target = next character\n",
    "        return x, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97cbf220-a2b8-4140-a252-8c782da78039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../rtl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "302a7a1d-4c5d-4dce-9fc5-f80351208144",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "class LSTMLayerLMUL(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, use_lmul=False, M=7):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.use_lmul = use_lmul\n",
    "        self.M = M\n",
    "        self.W = nn.Linear(input_size + hidden_size, 4*hidden_size)\n",
    "\n",
    "    def forward(self, x_t, h_prev, c_prev):\n",
    "        combined = torch.cat((x_t, h_prev), dim=1)\n",
    "\n",
    "        if self.use_lmul:\n",
    "            W = self.W.weight\n",
    "            b = self.W.bias\n",
    "            B, I = combined.shape\n",
    "            O, _ = W.shape\n",
    "            prod = lmul(combined.unsqueeze(1), W.unsqueeze(0), M=self.M)\n",
    "            gates = prod.sum(dim=2) + b\n",
    "        else:\n",
    "            gates = self.W(combined)\n",
    "\n",
    "        i, f, g, o = torch.chunk(gates, 4, dim=1)\n",
    "        i = torch.sigmoid(i)\n",
    "        f = torch.sigmoid(f)\n",
    "        o = torch.sigmoid(o)\n",
    "        g = torch.tanh(g)\n",
    "\n",
    "        if self.use_lmul:\n",
    "            c_t = lmul(f, c_prev, M=self.M) + lmul(i, g, M=self.M)\n",
    "            h_t = lmul(o, torch.tanh(c_t), M=self.M)\n",
    "        else:\n",
    "            c_t = f * c_prev + i * g\n",
    "            h_t = o * torch.tanh(c_t)\n",
    "\n",
    "        return h_t, c_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ffd8793d-2b74-48aa-ace0-3071b36234eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyLMUL_LLM(nn.Module):\n",
    "    def __init__(self, vocab, hidden=128, use_lmul=False, M=7):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden\n",
    "        self.use_lmul = use_lmul\n",
    "\n",
    "        self.embed = nn.Embedding(vocab, hidden)\n",
    "        self.lstm = LSTMLayerLMUL(hidden, hidden, use_lmul, M)\n",
    "        self.fc = nn.Linear(hidden, vocab)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, T = x.size()\n",
    "        h = torch.zeros(B, self.hidden_size)\n",
    "        c = torch.zeros(B, self.hidden_size)\n",
    "\n",
    "        for t in range(T):\n",
    "            x_t = self.embed(x[:, t])\n",
    "            h, c = self.lstm(x_t, h, c)\n",
    "\n",
    "        logits = self.fc(h)\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3194a850-bab3-4c5d-9f8e-910a3e5e9705",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader, epochs=5, lr=3e-4):\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total = 0\n",
    "        for x, y in loader:\n",
    "            opt.zero_grad()\n",
    "            logits = model(x)\n",
    "\n",
    "            loss = F.cross_entropy(logits, y[:, -1])\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            total += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}, loss={total/len(loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f21edd5-4311-437c-b99f-e080119c7385",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate(model, dataset, start=\"A\", length=200, temperature=1.0):\n",
    "    model.eval()\n",
    "\n",
    "    chars = [dataset.stoi[c] for c in start]\n",
    "    h = torch.zeros(1, model.hidden_size)\n",
    "    c = torch.zeros(1, model.hidden_size)\n",
    "    # prime with prefix\n",
    "    for ch in chars:\n",
    "        x_t = model.embed(torch.tensor([ch]))\n",
    "        h, c = model.lstm(x_t, h, c)\n",
    "\n",
    "    out = start\n",
    "    token = chars[-1]\n",
    "\n",
    "    for _ in range(length):\n",
    "        logits = model.fc(h) / temperature\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        token = torch.multinomial(probs, num_samples=1).item()\n",
    "\n",
    "        out += dataset.itos[token]\n",
    "\n",
    "        x_t = model.embed(torch.tensor([token]))\n",
    "        h, c = model.lstm(x_t, h, c)\n",
    "\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b571c80-98d5-485c-8c8d-e482350f7ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "text = requests.get(url).text\n",
    "sentences = text.split(\"\\n\")\n",
    "new_sentences = []\n",
    "for i in range(0, len(sentences), 5):\n",
    "    #every 5 sentences, I merge\n",
    "    new_sentences.append(\"\\n\".join(sentences[i:i+5]))\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8209026-8f8a-45a7-a4f0-d0366271f4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8001"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4718183-1930-4843-b93a-0d87e661bae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, loss=1.5726\n",
      "Epoch 2, loss=1.2334\n",
      "Epoch 3, loss=1.1032\n",
      "Epoch 4, loss=1.0050\n",
      "Epoch 5, loss=0.9164\n",
      "Epoch 6, loss=0.8370\n",
      "Epoch 7, loss=0.7588\n",
      "Epoch 8, loss=0.6837\n",
      "Epoch 9, loss=0.6058\n",
      "Epoch 10, loss=0.5381\n"
     ]
    }
   ],
   "source": [
    "#we dont need to run this cell anymore; its JUST for trainin and we save the weights anyways\n",
    "dataset = CharDatasetFixed(new_sentences[0:1000], pad_char=\" \", seq_len=128)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "#Standard FP32 LSTM (we dont use LMUL to train because gradienting using operations in LMUL is crazy cringe and not possible)\n",
    "model_fp32 = TinyLMUL_LLM(dataset.vocab, hidden=128, use_lmul=False)\n",
    "train(model_fp32, loader, epochs=10)\n",
    "\n",
    "#Save the FP32 weights\n",
    "torch.save(model_fp32.state_dict(), \"tiny_llm_fp32.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f689c151-dd96-404e-90e3-f34b1c8cecb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exquisite fre sastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Exquisite\"\n",
    "print(generate(model_fp32, dataset, start=prompt, length=300, temperature=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcdb6992-909d-42ca-88c8-649100fe98bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TinyLMUL_LLM(\n",
       "  (embed): Embedding(61, 128)\n",
       "  (lstm): LSTMLayerLMUL(\n",
       "    (W): Linear(in_features=256, out_features=512, bias=True)\n",
       "  )\n",
       "  (fc): Linear(in_features=128, out_features=61, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_lmul = TinyLMUL_LLM(dataset.vocab, hidden=128, use_lmul=True)\n",
    "\n",
    "#Load the FP32-trained weights, but we use the LSTM with LMUL operation\n",
    "model_lmul.load_state_dict(torch.load(\"tiny_llm_fp32.pth\"))\n",
    "model_lmul.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2286881-3257-456b-8aa0-a7ff0388a2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "LMUL LSTM output:\n",
      " Exquisite fre sastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare ssastare\n"
     ]
    }
   ],
   "source": [
    "lmul_text = generate(model_lmul, dataset, start=prompt, length=300, temperature=0.01)\n",
    "print(\"\\nLMUL LSTM output:\\n\", lmul_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "94436644-d791-4bc8-8a76-613077fbed31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b1a6374-18f7-4033-9cd6-cedbc47b58ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 1000\n",
      "Test size: 500\n"
     ]
    }
   ],
   "source": [
    "train_sentences = new_sentences[0:1000]\n",
    "test_sentences = new_sentences[1000:1500]\n",
    "\n",
    "test_dataset = CharDatasetFixed(test_sentences, pad_char=\" \", seq_len=128)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "print(f\"Train size: {len(train_sentences)}\")\n",
    "print(f\"Test size: {len(test_sentences)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13f88161-576d-4eb7-aaef-2ceb511f342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def calculate_perplexity(model, loader):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    total_tokens = 0\n",
    "    \n",
    "    for x, y in loader:\n",
    "        B, T = x.size()\n",
    "        h = torch.zeros(B, model.hidden_size)\n",
    "        c = torch.zeros(B, model.hidden_size)\n",
    "        \n",
    "        losses = []\n",
    "        for t in range(T):\n",
    "            x_t = model.embed(x[:, t])\n",
    "            h, c = model.lstm(x_t, h, c)\n",
    "            logits = model.fc(h)\n",
    "            \n",
    "            loss = F.cross_entropy(logits, y[:, t], reduction='sum')\n",
    "            losses.append(loss.item())\n",
    "            total_tokens += B\n",
    "        \n",
    "        total_loss += sum(losses)\n",
    "    \n",
    "    avg_loss = total_loss / total_tokens\n",
    "    perplexity = np.exp(avg_loss)\n",
    "    \n",
    "    return perplexity, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "938b440e-8787-4535-9e5f-fac5b08c5bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FP32 Perplexity: 20.59\n",
      "LMUL Perplexity: 21.85\n",
      "Difference: +6.10%\n"
     ]
    }
   ],
   "source": [
    "fp32_perplexity, fp32_loss = calculate_perplexity(model_fp32, test_loader)\n",
    "print(f\"FP32 Perplexity: {fp32_perplexity:.2f}\")\n",
    "\n",
    "lmul_perplexity, lmul_loss = calculate_perplexity(model_lmul, test_loader)\n",
    "print(f\"LMUL Perplexity: {lmul_perplexity:.2f}\")\n",
    "\n",
    "perplexity_pct = (lmul_perplexity - fp32_perplexity) / fp32_perplexity * 100\n",
    "print(f\"Difference: {perplexity_pct:+.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e6aa8ff-d13b-42ce-ac89-418bbe761f8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "perplexities = [fp32_perplexity, lmul_perplexity]\n",
    "plt.bar(['FP32', 'LMUL'], perplexities)\n",
    "plt.ylabel('Perplexity')\n",
    "plt.title('Perplexity Comparison')\n",
    "plt.savefig('perplexity.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9823a348-9570-43c0-8300-0e186f2160af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
